# Implementation of a Transformer from scratch
Here I provide an implementation of the encoder-decoder transformer architecture based on the orginal ["Attention is all you need"](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) paper.
I train this model based on some random data and also test its inference process.

## Run
Simply run:

```python
python main.py
```

